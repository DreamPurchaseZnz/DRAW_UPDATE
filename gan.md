# GAN
The picture come from [znxlwm](https://github.com/znxlwm/tensorflow-MNIST-GAN-DCGAN)

![GAN](./Pic/tensorflow_GAN.png)

![DCGAN](./Pic/tensorflow_GAN.png)

Draw on the idea above, we find that: 

> The final layer of generator which is imposed on the sigmoid activation is hard to train. However if we change the activation to tanh,
the model is easy to train.
